{
    "tracked_experiments": 11,
    "experiments": [
        {
            "tracked_experiments": 1,
            "experiments": [
                {
                    "member_name": "Ndizeye Lesly",
                    "experiment_number": 1,
                    "timestamp": "2025-11-14T02:35:17.274882",
                    "hyperparameters": {
                        "learning_rate": 0.0001,
                        "gamma": 0.99,
                        "batch_size": 32,
                        "epsilon_start": 1.0,
                        "epsilon_end": 0.05,
                        "epsilon_decay": 0.1
                    },
                    "observed_behavior": "Agent trained successfully",
                    "final_reward": null,
                    "notes": "Baseline hyperparameters"
                }
            ]
        },
        {
            "member_name": "Nicolas Muhigi",
            "experiment_number": 1,
            "timestamp": "2025-11-16T00:54:12.865236",
            "hyperparameters": {
                "learning_rate": 1e-06,
                "gamma": 0.999,
                "batch_size": 32,
                "epsilon_start": 0.9,
                "epsilon_end": 0.01,
                "epsilon_decay": 0.1
            },
            "observed_behavior": "Training completed",
            "final_reward": null,
            "notes": "Very slow learning with long-term reward focus"
        },
        {
            "member_name": "Nicolas Muhigi",
            "experiment_number": 2,
            "timestamp": "2025-11-16T14:36:46.402048",
            "hyperparameters": {
                "learning_rate": 0.001,
                "gamma": 0.9,
                "batch_size": 64,
                "epsilon_start": 1.0,
                "epsilon_end": 0.2,
                "epsilon_decay": 0.1
            },
            "observed_behavior": "Training completed",
            "final_reward": null,
            "notes": "High learning rate prioritizing short-term rewards; fast but unstable learning"
        },
        {
            "member_name": "Nicolas Muhigi",
            "experiment_number": 3,
            "timestamp": "2025-11-16T15:39:55.891438",
            "hyperparameters": {
                "learning_rate": 5e-05,
                "gamma": 0.99,
                "batch_size": 8,
                "epsilon_start": 1.0,
                "epsilon_end": 0.05,
                "epsilon_decay": 0.1
            },
            "observed_behavior": "Training completed",
            "final_reward": null,
            "notes": "Tiny batch size with long exploration phase; noisy but robust learning"
        },
        {
            "member_name": "Nicolas Muhigi",
            "experiment_number": 4,
            "timestamp": "2025-11-16T18:07:20.287587",
            "hyperparameters": {
                "learning_rate": 0.0002,
                "gamma": 0.995,
                "batch_size": 128,
                "epsilon_start": 1.0,
                "epsilon_end": 0.01,
                "epsilon_decay": 0.1
            },
            "observed_behavior": "Training completed",
            "final_reward": null,
            "notes": "Large batch with rapid epsilon decay; stable gradients but fast convergence"
        },
        {
            "member_name": "Nicolas Muhigi",
            "experiment_number": 5,
            "timestamp": "2025-11-16T19:33:44.927399",
            "hyperparameters": {
                "learning_rate": 7e-05,
                "gamma": 0.999,
                "batch_size": 32,
                "epsilon_start": 0.5,
                "epsilon_end": 0.05,
                "epsilon_decay": 0.1
            },
            "observed_behavior": "Training completed",
            "final_reward": null,
            "notes": "Semi-greedy early behavior; high gamma for long-term reward optimization"
        },
        {
            "member_name": "Nicolas Muhigi",
            "experiment_number": 6,
            "timestamp": "2025-11-16T20:57:10.994488",
            "hyperparameters": {
                "learning_rate": 0.0003,
                "gamma": 0.96,
                "batch_size": 32,
                "epsilon_start": 1.0,
                "epsilon_end": 0.6,
                "epsilon_decay": 0.1
            },
            "observed_behavior": "Training completed",
            "final_reward": null,
            "notes": "Highly exploratory agent; tests wide state-space coverage"
        },
        {
            "member_name": "Nicolas Muhigi",
            "experiment_number": 7,
            "timestamp": "2025-11-16T22:13:49.401762",
            "hyperparameters": {
                "learning_rate": 2e-05,
                "gamma": 0.98,
                "batch_size": 48,
                "epsilon_start": 1.0,
                "epsilon_end": 0.02,
                "epsilon_decay": 0.1
            },
            "observed_behavior": "Training completed",
            "final_reward": null,
            "notes": "Very slow epsilon decay; agent stays random for most of training"
        },
        {
            "member_name": "Nicolas Muhigi",
            "experiment_number": 8,
            "timestamp": "2025-11-16T23:27:06.913159",
            "hyperparameters": {
                "learning_rate": 0.0001,
                "gamma": 0.99,
                "batch_size": 32,
                "epsilon_start": 1.0,
                "epsilon_end": 0.005,
                "epsilon_decay": 0.1
            },
            "observed_behavior": "Training completed",
            "final_reward": null,
            "notes": "Very greedy final policy; strong focus on exploitation performance"
        },
        {
            "member_name": "Nicolas Muhigi",
            "experiment_number": 9,
            "timestamp": "2025-11-17T01:05:33.307017",
            "hyperparameters": {
                "learning_rate": 0.0008,
                "gamma": 0.92,
                "batch_size": 64,
                "epsilon_start": 0.3,
                "epsilon_end": 0.01,
                "epsilon_decay": 0.1
            },
            "observed_behavior": "Training completed",
            "final_reward": null,
            "notes": "High learning rate with low exploration; tests unstable but fast learners"
        },
        {
            "member_name": "Nicolas Muhigi",
            "experiment_number": 10,
            "timestamp": "2025-11-17T02:24:06.709471",
            "hyperparameters": {
                "learning_rate": 0.0003,
                "gamma": 0.995,
                "batch_size": 32,
                "epsilon_start": 1.0,
                "epsilon_end": 0.02,
                "epsilon_decay": 0.1
            },
            "observed_behavior": "Training completed",
            "final_reward": null,
            "notes": "Balanced baseline setup; smooth epsilon decay with high gamma"
        }
    ]
}